# Syst√®me de Retrieval Augmented Generation (RAG) pour Documents Scientifiques

## Vue d'ensemble

Ce projet impl√©mente un syst√®me de RAG (Retrieval Augmented Generation) sp√©cialis√© pour l'analyse de documents scientifiques historiques au format XML-TEI. Le syst√®me permet d'interroger un corpus de documents en fran√ßais et de g√©n√©rer des r√©ponses pr√©cises et sourc√©es en utilisant des mod√®les de langage de pointe.

## Architecture du Pipeline

L'architecture actuelle est principalement de type **RAG Na√Øf** avec des √©l√©ments de **Retrieve-and-Rerank**. Voici les composants principaux :

### 1. Traitement des Documents

-   **Chargement des documents** : Les fichiers XML-TEI sont charg√©s depuis les emplacements par d√©faut (`./`, `data/`) ou via t√©l√©chargement utilisateur (sauvegard√©s dans `data/uploaded/`).
-   **Parsing XML-TEI** : Extraction du texte et des m√©tadonn√©es (titre, date, ann√©e, personnes mentionn√©es, et contenu textuel complet).
-   **D√©coupage en fragments** : Utilisation de `RecursiveCharacterTextSplitter` avec une taille de fragment de 2500 caract√®res et un chevauchement de 800 caract√®res.

### 2. Cr√©ation des Embeddings

Le syst√®me propose deux options pour les embeddings :

-   **Traitement en temps r√©el** : Utilisation du mod√®le "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2". Les embeddings et l'index FAISS sont sauvegard√©s localement dans `vector_store/`.
-   **Embeddings pr√©-calcul√©s** : Option d'utiliser des embeddings d√©j√† g√©n√©r√©s et stock√©s dans `embeddings/`. Le mod√®le d'embedding utilis√© pour ces fichiers est indiqu√© dans leurs m√©tadonn√©es (`embeddings/document_metadata.pkl`). Si le nom du mod√®le n'est pas trouv√© dans les m√©tadonn√©es, "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" est utilis√© par d√©faut.

### 3. M√©canisme de R√©cup√©ration (Retrieval)

-   **Base de donn√©es vectorielle** : Utilisation de FAISS pour stocker et r√©cup√©rer les fragments de documents.
-   **Retriever MMR** : Impl√©mentation de Maximum Marginal Relevance pour √©quilibrer pertinence et diversit√©.
    ```python
    retriever = vectordb.as_retriever(
        search_type="mmr",
        search_kwargs={'k': 3, 'fetch_k': 20} # Mise √† jour des valeurs k et fetch_k
    )
    ```

### 4. G√©n√©ration de R√©ponses

-   **Mod√®les de langage support√©s** (s√©lectionnables via l'interface utilisateur) :

    Via HuggingFace (n√©cessite une cl√© API Hugging Face) :
    -   Zephyr (HuggingFaceH4/zephyr-7b-beta) - *S√©lectionn√© via l'option "Zephyr"*
    -   Mistral (mistralai/Mistral-7B-Instruct-v0.3) - *S√©lectionn√© via l'option "Mistral"*
    -   Phi (microsoft/Phi-3-mini-4k-instruct) - *S√©lectionn√© via l'option "Phi"*

    Via OpenRouter (n√©cessite une cl√© API OpenRouter) :
    -   Llama 4 Maverick (meta-llama/llama-4-maverick:free) - *S√©lectionn√© via l'option "Llama"*

-   **Structure du Prompt** :
    -   Un **Prompt Syst√®me fixe** (non modifiable par l'utilisateur) instruit le mod√®le sur son r√¥le et l'importance du sour√ßage.
        ```
        Tu es un agent RAG charg√© de g√©n√©rer des r√©ponses en t'appuyant exclusivement sur les informations fournies dans les documents de r√©f√©rence.

        IMPORTANT: Pour chaque information ou affirmation dans ta r√©ponse, tu DOIS indiquer explicitement le num√©ro de la source (Source 1, Source 2, etc.) dont provient cette information.
        ```
    -   Un **Prompt de Requ√™te Utilisateur par d√©faut (COSTAR)** qui peut √™tre personnalis√© dans l'interface.
    -   Des **Instructions Additionnelles** sont dynamiquement ajout√©es pour le r√©f√©rencement des sources et le contexte documentaire.

## Fonctionnalit√©s Principales

1.  **Interface utilisateur Streamlit** avec configuration dans la barre lat√©rale.
2.  **Options de traitement flexibles** :
    -   Utilisation d'embeddings pr√©-calcul√©s (charg√©s depuis `embeddings/`).
    -   Traitement en temps r√©el des documents (sauvegarde dans `vector_store/`).
    -   Option pour utiliser uniquement les fichiers t√©l√©charg√©s par l'utilisateur.
3.  **Personnalisation du prompt de requ√™te** via le cadre COSTAR dans la barre lat√©rale.
4.  **Visualisation des sources** utilis√©es pour g√©n√©rer la r√©ponse (titre, date, fichier, personnes mentionn√©es, extrait du contenu) pour v√©rifier la fiabilit√©.
5.  **Support multilingue** optimis√© pour les documents scientifiques en fran√ßais (notamment via le mod√®le d'embedding `paraphrase-multilingual-MiniLM-L12-v2`).
6.  **Gestion des erreurs OCR** (via instructions dans le prompt COSTAR) avec demande de niveaux de confiance pour les informations extraites.
7.  **Affichage d'informations sur les mod√®les LLM** s√©lectionnables et leurs caract√©ristiques.
8.  **Gestion et affichage des fichiers XML t√©l√©charg√©s** par l'utilisateur.

## Utilisation

1.  Configurer les cl√©s API dans la barre lat√©rale (Hugging Face, et OpenRouter si le mod√®le Llama 4 est utilis√©).
2.  Choisir entre l'utilisation d'embeddings pr√©-calcul√©s ou le traitement en temps r√©el des documents.
    -   Si traitement en temps r√©el, sp√©cifier si seuls les documents t√©l√©charg√©s doivent √™tre utilis√©s.
3.  S√©lectionner un mod√®le LLM parmi les options propos√©es.
4.  Si traitement en temps r√©el :
    -   T√©l√©charger des documents XML-TEI via l'interface (optionnel si utilisation du corpus par d√©faut).
    -   Cliquer sur "Traiter les documents".
5.  Si embeddings pr√©-calcul√©s :
    -   S'assurer que le dossier `embeddings/` contient les fichiers `faiss_index/` (avec `index.faiss` et `index.pkl`) et `document_metadata.pkl`.
    -   Cliquer sur "Charger embeddings pr√©-calcul√©s".
6.  Poser des questions dans l'interface de chat.
7.  Optionnellement, modifier le prompt de requ√™te COSTAR dans la barre lat√©rale.

## Structure du Syst√®me

Le syst√®me est organis√© autour des fonctions principales suivantes :
-   `parse_xmltei_document` : Extraction du contenu et des m√©tadonn√©es des fichiers XML-TEI.
-   `load_documents` : Chargement des documents XML-TEI depuis le disque ou les fichiers t√©l√©charg√©s.
-   `split_documents` : D√©coupage des documents en fragments.
-   `embeddings_on_local_vectordb` : Cr√©ation des embeddings en temps r√©el et de la base vectorielle FAISS (sauvegard√©e dans `LOCAL_VECTOR_STORE_DIR`).
-   `load_precomputed_embeddings` : Chargement des embeddings pr√©-calcul√©s depuis `EMBEDDINGS_DIR`.
-   `query_llm` : Interrogation du mod√®le de langage avec la requ√™te utilisateur, le contexte r√©cup√©r√© et la gestion des diff√©rents mod√®les LLM.
-   `process_documents` : Orchestration du processus de traitement des documents (chargement, d√©coupage, cr√©ation d'embeddings).
-   `input_fields` : Configuration de la barre lat√©rale Streamlit (cl√©s API, s√©lection de mod√®le, options de traitement, upload de fichiers, configuration du prompt).
-   `boot` : Fonction principale de l'application Streamlit, initialise l'interface et g√®re le flux de l'application.

## üîÑ Format des fichiers XML-TEI support√©s

L'application est con√ßue pour traiter des documents XML-TEI avec les balises suivantes :
-   `<tei:titleStmt>/<tei:title>` pour le titre du document.
-   `<tei:sourceDesc>/<tei:p>/<tei:date>` pour la date. Si cette balise n'est pas trouv√©e, le syst√®me tente subsidiairement d'extraire la date depuis `<tei:sourceDesc>/<tei:p>`.
-   `<tei:p>` pour les paragraphes de contenu.
-   `<tei:persName>` pour les noms de personnes mentionn√©es.
La fonction `extract_year` tente d'extraire l'ann√©e (format AAAA) √† partir de la cha√Æne de date.

## üìÑ Licence

Ce projet est sous une licence open source MIT.

## ü§ù Contributions

Le projet est pr√©par√© par [Mikhail Biriuchinskii](https://www.linkedin.com/in/mikhail-biriuchinskii/), ing√©nieur en Traitement Automatique des Langues, √©quipe ObTIC, Sorbonne Universit√©.

Pour d√©couvrir d'autres projets de l'√©quipe ObTIC ainsi que les formations propos√©es, consultez le site : https://obtic.sorbonne-universite.fr/
